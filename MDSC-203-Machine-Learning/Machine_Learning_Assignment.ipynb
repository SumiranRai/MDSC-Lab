{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SumiranRai/MDSC-Lab/blob/main/MDSC-203-Machine-Learning/Machine_Learning_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1CMk60iq2F6"
      },
      "source": [
        "# Machine Learning Assignment\n",
        "\n",
        "By Sumiran Rai\n",
        "\n",
        "Regd. No. - 24040208007"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbEn-LO-r2Qd"
      },
      "source": [
        "### Understanding the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78Davrjuq6DR"
      },
      "source": [
        "Importing required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Bp5Tr7bHaxZG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "405567c3-360f-47ff-99b6-89ac07e99aff"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-1-1517b9dcce76>, line 1)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-1517b9dcce76>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    .import numpy as np\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        ".import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v06rL0yaq9ym"
      },
      "source": [
        "Loading the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "id": "7k3SGMy-erht",
        "outputId": "e343c05a-9a1f-40f6-bf14-74b979c7ca0f"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'pd' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-e204dc412a66>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/sample_data/diabetes_012_health_indicators_BRFSS2015.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
          ]
        }
      ],
      "source": [
        "data = pd.read_csv('/content/sample_data/diabetes_012_health_indicators_BRFSS2015.csv')\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxvDUDS1rAqq"
      },
      "source": [
        "Shape of the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KlAmdT9BfDAj"
      },
      "outputs": [],
      "source": [
        "print(data.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rogGkh51rCyX"
      },
      "source": [
        "Data type of each feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nxaCmZ7rNwAX"
      },
      "outputs": [],
      "source": [
        "types = data.dtypes\n",
        "print(types)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVvjRkUmrIpX"
      },
      "source": [
        "Let's understand the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qs0F7h3SOoFD"
      },
      "outputs": [],
      "source": [
        "from pandas import set_option\n",
        "with pd.option_context('display.width', 150, 'display.precision', 2):\n",
        "  description = data.describe()\n",
        "  print(description)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "puIRRABfrOaE"
      },
      "source": [
        "###Dataset is Imbalanced!\n",
        "\n",
        "0 - No Diabetes\n",
        "\n",
        "1 - Pre-Diabetic\n",
        "\n",
        "2 - Diabetic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xPuSSX51O07W"
      },
      "outputs": [],
      "source": [
        "class_counts = data.groupby('Diabetes_012').size()\n",
        "print(class_counts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SkJDoiBvrpiL"
      },
      "source": [
        "Correlations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xu1CUPSoo8sr"
      },
      "outputs": [],
      "source": [
        "with pd.option_context('display.width', 150, 'display.precision', 2):\n",
        "  correlations = data.corr(method='pearson')\n",
        "  print(correlations)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LOnTBhIHrtDd"
      },
      "source": [
        "Skewness"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AJESHpbfqUDB"
      },
      "outputs": [],
      "source": [
        "skew = data.skew()\n",
        "print(skew)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvkUxF5arvdI"
      },
      "source": [
        "### Visualizing the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ki4lF63tcPN"
      },
      "source": [
        "#### Histograms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8xqeHhJrqxbm"
      },
      "outputs": [],
      "source": [
        "# Create histograms\n",
        "fig = data.hist(figsize=(10, 6), bins=20, grid=True)\n",
        "\n",
        "# Adjust layout and font sizes\n",
        "plt.tight_layout()\n",
        "plt.subplots_adjust(hspace=1, wspace=1)  # Adjust spacing between subplots\n",
        "\n",
        "# Reduce font size for better readability\n",
        "for ax in fig.flatten():\n",
        "    ax.set_xlabel(ax.get_xlabel(), fontsize=10)\n",
        "    ax.set_ylabel(ax.get_ylabel(), fontsize=10)\n",
        "    ax.set_title(ax.get_title(), fontsize=12)\n",
        "    ax.tick_params(axis='both', labelsize=8)  # Reduce tick label font size\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXmW1dLGtv_N"
      },
      "source": [
        "#### Density Plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ovTSQQxsA-2"
      },
      "outputs": [],
      "source": [
        "#data.plot(kind='density', subplots=True, layout=(5,5), sharex=False)\n",
        "#plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8Dpgu9audfz"
      },
      "source": [
        "Box and Whisker Plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sc642PLitlkz"
      },
      "outputs": [],
      "source": [
        "axes = data.plot(kind='box', subplots=True, layout=(5, 5), sharex=False, sharey=False, figsize=(12, 10), patch_artist=True, vert=True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.subplots_adjust(hspace=0.5, wspace=0.5)\n",
        "\n",
        "if isinstance(axes, np.ndarray):  # If axes is an array\n",
        "    axes = axes.flatten()\n",
        "else:  # If only one subplot exists (Series case)\n",
        "    axes = [axes]\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6zXkCyiwhRy"
      },
      "source": [
        "#### Correlation matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xRCnAut9t4-n"
      },
      "outputs": [],
      "source": [
        "# Plot correlation matrix\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "cax = ax.matshow(correlations, vmin=-1, vmax=1, cmap='coolwarm')\n",
        "fig.colorbar(cax)\n",
        "\n",
        "# Set ticks and labels\n",
        "ticks = np.arange(len(data.columns))\n",
        "ax.set_xticks(ticks)\n",
        "ax.set_yticks(ticks)\n",
        "ax.set_xticklabels(data.columns, rotation=90)  # Rotate for better readability\n",
        "ax.set_yticklabels(data.columns)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6sJHjpEuqXd"
      },
      "source": [
        "Generic Correlation Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N4OjkunRua23"
      },
      "outputs": [],
      "source": [
        "#plot correlation matrix\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111)\n",
        "cax = ax.matshow(correlations, vmin=-1, vmax=1, cmap='coolwarm')\n",
        "fig.colorbar(cax)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOQjVXhXyk6D"
      },
      "source": [
        "#### Scatter Plot\n",
        "\n",
        "from pandas.plotting import scatter_matrix  \n",
        "\n",
        "fig = scatter_matrix(data, figsize=(10, 10), diagonal='hist', marker='o', alpha=0.7, s=10, hist_kwds={'bins': 20})\n",
        "\n",
        "for ax in fig.flatten():\n",
        "    ax.xaxis.label.set_fontsize(10)\n",
        "    ax.yaxis.label.set_fontsize(10)\n",
        "    ax.tick_params(axis='both', labelsize=8)\n",
        "\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0uBOcRO1L6B"
      },
      "source": [
        "### Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YlWZGl-C1h8n"
      },
      "source": [
        "#### Rescale Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4PcYGpJI0lCW"
      },
      "outputs": [],
      "source": [
        "from numpy import set_printoptions\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "array = data.values\n",
        "\n",
        "# First column (index 0) is the target (Y)\n",
        "Y = array[:, 0]\n",
        "\n",
        "# Remaining 21 columns (index 1 to 21) are features (X)\n",
        "X = array[:, 1:22]\n",
        "\n",
        "# Apply Min-Max Scaling to features only\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "rescaledX = scaler.fit_transform(X)\n",
        "\n",
        "# Print first 5 rows of scaled data\n",
        "set_printoptions(precision=3)\n",
        "print(rescaledX[0:5, :])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LOWgaHQ2582"
      },
      "source": [
        "#### Standardize Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XRZ6b6gd2FXo"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "array = data.values\n",
        "\n",
        "# separate array into input and output components\n",
        "X = array[:, 1:22]\n",
        "Y = array[:, 0]\n",
        "scaler = StandardScaler().fit(X)\n",
        "rescaledX = scaler.transform(X)\n",
        "# summarize transformed data\n",
        "set_printoptions(precision=3)\n",
        "print(rescaledX[0:5,:])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "InLMWzaK3aVI"
      },
      "source": [
        "#### Normalize Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kVcynE2j3Ri-"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import Normalizer\n",
        "\n",
        "array = data.values\n",
        "# separate array into input and output components\n",
        "X = array[:, 1:22]\n",
        "Y = array[:, 0]\n",
        "scaler = Normalizer().fit(X)\n",
        "normalizedX = scaler.transform(X)\n",
        "# summarize transformed data\n",
        "set_printoptions(precision=3)\n",
        "print(normalizedX[0:5,:])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQzzZXql32LU"
      },
      "source": [
        "#### Binarize Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lYXROT4J3pc0"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import Binarizer\n",
        "\n",
        "array = data.values\n",
        "# separate array into input and output components\n",
        "X = array[:,1:22]\n",
        "Y = array[:,0]\n",
        "binarizer = Binarizer(threshold=0.0).fit(X)\n",
        "binaryX = binarizer.transform(X)\n",
        "# summarize transformed data\n",
        "set_printoptions(precision=3)\n",
        "print(binaryX[0:5,:])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ETyfxQ18yWW"
      },
      "source": [
        "### Feature Selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "raBwwFpTABB_"
      },
      "source": [
        "#### Univariate Selection\n",
        "\n",
        "Statistical tests can be used to select those features that have the strongest relationship with\n",
        "the output variable.\n",
        "The scikit-learn library provides the SelectKBest class2\n",
        "that can be used\n",
        "with a suite of different statistical tests to select a specific number of features. The example\n",
        "below uses the chi-squared (chi2\n",
        ") statistical test for non-negative features to select 11 of the best\n",
        "features from the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xccywB_36Y1j"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Feature selection\n",
        "X = data.iloc[:, 1:22]  # Selecting feature columns\n",
        "Y = data.iloc[:, 0]     # Target column\n",
        "\n",
        "# Applying SelectKBest\n",
        "test = SelectKBest(score_func=chi2, k=11)\n",
        "fit = test.fit(X, Y)\n",
        "\n",
        "# Get selected feature indices\n",
        "selected_indices = fit.get_support(indices=True)\n",
        "\n",
        "# Get the feature names\n",
        "selected_features = X.columns[selected_indices]\n",
        "\n",
        "# Print scores and selected feature names\n",
        "print(\"Feature Scores:\\n\", fit.scores_)\n",
        "print(\"\\nSelected Features:\\n\", selected_features)\n",
        "\n",
        "# Transform dataset to include only selected features\n",
        "X_selected = fit.transform(X)\n",
        "\n",
        "# Convert to DataFrame for better readability\n",
        "X_selected_df = pd.DataFrame(X_selected, columns=selected_features)\n",
        "\n",
        "# Display first 5 rows of selected features\n",
        "print(X_selected_df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6X9nBrFAhXb"
      },
      "source": [
        "#### Recursive Feature Elimination\n",
        "\n",
        "The Recursive Feature Elimination (or RFE) works by recursively removing attributes and\n",
        "building a model on those attributes that remain. It uses the model accuracy to identify which attributes (and combination of attributes) contribute the most to predicting the target attribute."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OlPzBwbD9Xn6"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import pandas as pd\n",
        "\n",
        "# Convert NumPy array to DataFrame (if necessary)\n",
        "if isinstance(data, pd.DataFrame):  # If data is already a DataFrame\n",
        "    X = data.iloc[:, 1:22]  # Select feature columns\n",
        "    Y = data.iloc[:, 0]  # Target variable\n",
        "    feature_names = X.columns  # Get column names\n",
        "else:  # If data is a NumPy array\n",
        "    feature_names = [f\"Feature_{i}\" for i in range(1, 22)]  # Create dummy labels\n",
        "    X = pd.DataFrame(data[:, 1:22], columns=feature_names)  # Convert to DataFrame\n",
        "    Y = pd.Series(data[:, 0])  # Convert target variable to a Pandas Series\n",
        "\n",
        "# Define model\n",
        "model = LogisticRegression(solver='liblinear')\n",
        "\n",
        "# Apply RFE\n",
        "num_features = 7  # Change as needed\n",
        "rfe = RFE(estimator=model, n_features_to_select=num_features)\n",
        "rfe.fit(X, Y)\n",
        "\n",
        "# Get selected feature names\n",
        "selected_features = X.columns[rfe.support_]\n",
        "\n",
        "# Print results\n",
        "print(f\"Selected {num_features} Features:\", list(selected_features))\n",
        "print(\"Feature Ranking:\", rfe.ranking_)\n",
        "\n",
        "# Create DataFrame with selected features\n",
        "X_selected_df = X.loc[:, rfe.support_]\n",
        "print(X_selected_df.head())  # Display first 5 rows\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4sWLFZRCPGC"
      },
      "source": [
        "#### Principal Component Analysis\n",
        "\n",
        "Principal Component Analysis (or PCA) uses linear algebra to transform the dataset into a\n",
        "compressed form. Generally this is called a data reduction technique. A property of PCA is that\n",
        "you can choose the number of dimensions or principal components in the transformed result."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbtzZPOiD2Tq"
      },
      "source": [
        "PCA with Feature Labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "33Ctz8kTCOtx"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Convert NumPy array to DataFrame if necessary\n",
        "if isinstance(data, pd.DataFrame):  # If data is already a DataFrame\n",
        "    X = data.iloc[:, 0:8]  # Select feature columns\n",
        "    feature_names = X.columns  # Get column names\n",
        "else:  # If data is a NumPy array\n",
        "    feature_names = [f\"Feature_{i}\" for i in range(8)]  # Create dummy labels\n",
        "    X = pd.DataFrame(data[:, 0:8], columns=feature_names)  # Convert to DataFrame\n",
        "\n",
        "# Apply PCA\n",
        "n_components = 1 # Change as needed\n",
        "pca = PCA(n_components=n_components)\n",
        "X_pca = pca.fit_transform(X)\n",
        "\n",
        "# Create a DataFrame with PCA components\n",
        "pca_df = pd.DataFrame(X_pca, columns=[f'PC{i+1}' for i in range(n_components)])\n",
        "\n",
        "# Print explained variance ratio\n",
        "print(\"Explained Variance Ratio:\", pca.explained_variance_ratio_)\n",
        "\n",
        "# Get feature contributions to principal components\n",
        "pca_components = pd.DataFrame(pca.components_, columns=feature_names,\n",
        "                              index=[f'PC{i+1}' for i in range(n_components)])\n",
        "print(\"\\nFeature Contributions to Each Principal Component:\\n\", pca_components)\n",
        "\n",
        "# Show the transformed PCA dataset\n",
        "print(\"\\nFirst 5 rows of transformed PCA features:\\n\", pca_df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-uWdoluEubH"
      },
      "source": [
        "Determine the Optimal Number of Components"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o6Y_B48gBNGK"
      },
      "outputs": [],
      "source": [
        "pca_full = PCA().fit(X)  # Fit PCA with all components\n",
        "explained_variance = np.cumsum(pca_full.explained_variance_ratio_)\n",
        "\n",
        "plt.plot(range(1, len(explained_variance)+1), explained_variance, marker='o', linestyle='--')\n",
        "plt.xlabel('Number of Principal Components')\n",
        "plt.ylabel('Cumulative Explained Variance')\n",
        "plt.title('Scree Plot')\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0czMuolrE6ZN"
      },
      "source": [
        " Automatic Selection (95% Variance)\n",
        "\n",
        " If the optimal number of principal components (PCs) is 1, it means that a single principal component explains most of the variance in your dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DgqtjZF7DwSl"
      },
      "outputs": [],
      "source": [
        "cumulative_variance = np.cumsum(pca_full.explained_variance_ratio_)\n",
        "optimal_components = np.argmax(cumulative_variance >= 0.95) + 1  # First index where â‰¥ 95%\n",
        "print(f\"Optimal number of components: {optimal_components}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEWgy19oFaTS"
      },
      "source": [
        "#### Feature Importance\n",
        "\n",
        "Bagged decision trees like Random Forest and Extra Trees can be used to estimate the importance\n",
        "of features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "neQVXUeKEz0Q"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "\n",
        "# Ensure `X` is a DataFrame (if `data` is available)\n",
        "if isinstance(data, pd.DataFrame):\n",
        "    X = data.iloc[:, 1:22]  # Feature columns\n",
        "    Y = data.iloc[:, 0]  # Target variable\n",
        "    feature_names = X.columns  # Get feature labels\n",
        "else:\n",
        "    feature_names = [f\"Feature_{i}\" for i in range(1, 22)]  # Create dummy labels\n",
        "    X = pd.DataFrame(array[:, 1:22], columns=feature_names)\n",
        "    Y = pd.Series(array[:, 0])  # Ensure Y is a Series\n",
        "\n",
        "# Feature importance with Extra Trees Classifier\n",
        "model = ExtraTreesClassifier(n_estimators=100, random_state=42)  # Use more trees for better stability\n",
        "model.fit(X, Y)\n",
        "\n",
        "# Get feature importance scores\n",
        "feature_importance = model.feature_importances_\n",
        "\n",
        "# Create DataFrame for better visualization\n",
        "importance_df = pd.DataFrame({\"Feature\": feature_names, \"Importance\": feature_importance})\n",
        "importance_df = importance_df.sort_values(by=\"Importance\", ascending=False)  # Sort by importance\n",
        "\n",
        "# Print sorted feature importance\n",
        "print(importance_df)\n",
        "\n",
        "# Optional: Plot the feature importance\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.barh(importance_df[\"Feature\"], importance_df[\"Importance\"], color='skyblue')\n",
        "plt.xlabel(\"Feature Importance Score\")\n",
        "plt.ylabel(\"Feature\")\n",
        "plt.title(\"Feature Importance using Extra Trees Classifier\")\n",
        "plt.gca().invert_yaxis()  # Reverse order for better visualization\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSXyVlBvGj6B"
      },
      "source": [
        "### Performance Evaluation of ML Algorithms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJ2geCupG4i-"
      },
      "source": [
        "#### Split into Train and Test Sets\n",
        "\n",
        "70% - Training set\n",
        "\n",
        "30% - Test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mzR7iYTcGJqF"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.exceptions import ConvergenceWarning\n",
        "import warnings\n",
        "\n",
        "# Ignore convergence warnings\n",
        "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.30, random_state=7)\n",
        "\n",
        "# Feature Scaling (Standardization)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Define & Train Logistic Regression\n",
        "model = LogisticRegression(solver='saga', max_iter=1000, C=1.0)  # C=1.0 (default regularization)\n",
        "model.fit(X_train, Y_train)\n",
        "\n",
        "# Evaluate Model\n",
        "accuracy = model.score(X_test, Y_test) * 100.0\n",
        "print(f\"Accuracy: {accuracy:.3f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0IKX6VuqIvrH"
      },
      "source": [
        "#### K-fold Cross Validation\n",
        "\n",
        "K-Fold Cross Validation is a technique to estimate model performance with lower variance than a single train-test split. It works by dividing the dataset into k equal parts (folds), where the model is trained on k-1 folds and tested on the remaining one. This process repeats k times, with each fold serving as the test set once.\n",
        "\n",
        "After training, we get k performance scores, which are averaged to provide a more reliable estimate of the model's performance. Common values of k are 3, 5, or 10, depending on dataset size. This method ensures the model is tested on different data, leading to a more generalizable evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OnurV-J4HbNm"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "# Define k-fold cross-validation\n",
        "num_folds = 10\n",
        "seed = 7\n",
        "kfold = KFold(n_splits=num_folds, shuffle=True, random_state=seed)  # Fixed issue\n",
        "\n",
        "# Normalize features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)  # Scale the entire dataset\n",
        "\n",
        "# Define model\n",
        "model = LogisticRegression(solver='saga', max_iter=1000)  # saga is better for large datasets\n",
        "\n",
        "# Evaluate model using cross-validation\n",
        "results = cross_val_score(model, X_scaled, Y, cv=kfold, scoring='accuracy')\n",
        "\n",
        "# Print results\n",
        "print(f\"Accuracy: {results.mean() * 100:.3f}% Â± {results.std() * 100:.3f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZkGs13iKVuC"
      },
      "source": [
        "#### Leave One Out Cross Validation\n",
        "\n",
        "This variation of cross validation is called leave-one-out cross\n",
        "validation. The result is a large number of performance measures that can be summarized in an effort to give a more reasonable estimate of the accuracy of your model on unseen data.\n",
        "\n",
        "A downside is that it can be a computationally more expensive procedure than k-fold cross\n",
        "validation.\n",
        "\n",
        "Leave-One-Out (LOO) is computationally expensive â†’ Not ideal for large datasets (250,000 instances)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VRdEwCa3KCjE"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "from sklearn.model_selection import LeaveOneOut, cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "# Normalize features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)  # Scale the entire dataset\n",
        "\n",
        "# Define Leave-One-Out Cross-Validation\n",
        "loocv = LeaveOneOut()\n",
        "\n",
        "# Define Model\n",
        "model = LogisticRegression(solver='saga', max_iter=1000)  # 'saga' is better for large datasets\n",
        "\n",
        "# Evaluate Model\n",
        "results = cross_val_score(model, X_scaled, Y, cv=loocv, scoring='accuracy')\n",
        "\n",
        "# Print Results\n",
        "print(f\"Accuracy: {results.mean() * 100:.3f}% Â± {results.std() * 100:.3f}%\")\n",
        "\"\"\"\n",
        "\n",
        "# Skipped evaluating because it took too much time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVOq_3wkLywf"
      },
      "source": [
        "#### Repeated Random Test-Train Splits\n",
        "\n",
        "Repeated Random Train-Test Splitting is a variation of k-fold cross-validation that repeatedly splits the dataset into training and testing sets. It offers:\n",
        "\n",
        "âœ” Faster evaluation than k-fold cross-validation.\n",
        "\n",
        "âœ” Lower variance than a single train-test split.\n",
        "\n",
        "âœ” More repetitions for improved accuracy.\n",
        "\n",
        "ðŸ”¹ Downside: Some data points may appear in multiple test sets, causing redundancy.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UmoR5IB0LRO_"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import ShuffleSplit, cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "# Normalize features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Define Shuffle Split CV\n",
        "n_splits = 10\n",
        "test_size = 0.33\n",
        "seed = 7\n",
        "shuffle_split = ShuffleSplit(n_splits=n_splits, test_size=test_size, random_state=seed)\n",
        "\n",
        "# Define Model\n",
        "model = LogisticRegression(solver='saga', max_iter=1000)  # 'saga' works well for large datasets\n",
        "\n",
        "# Evaluate Model\n",
        "results = cross_val_score(model, X_scaled, Y, cv=shuffle_split, scoring='accuracy')\n",
        "\n",
        "# Print Results\n",
        "print(f\"Accuracy: {results.mean() * 100:.3f}% Â± {results.std() * 100:.3f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSsSXIZaODCx"
      },
      "source": [
        "### ML Algorithm Performance Metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPF_zeD0PpW4"
      },
      "source": [
        "#### Classification Accuracy\n",
        "\n",
        "Classification accuracy is the number of correct predictions made as a ratio of all predictions\n",
        "made. This is the most common evaluation metric for classification problems, it is also the most\n",
        "misused. It is really only suitable when there are an equal number of observations in each class\n",
        "(which is rarely the case) and that all predictions and prediction errors are equally important,\n",
        "which is often not the case."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nd5g7EZwNPYg"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "# Normalize features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Define K-Fold CV\n",
        "kfold = KFold(n_splits=10, random_state=7, shuffle=True)  # Added shuffle for randomness\n",
        "\n",
        "# Define Model\n",
        "model = LogisticRegression(solver='saga', max_iter=1000)  # 'saga' for large datasets\n",
        "\n",
        "# Evaluate Model\n",
        "results = cross_val_score(model, X_scaled, Y, cv=kfold, scoring='accuracy')\n",
        "\n",
        "# Print Results\n",
        "print(f\"Accuracy: {results.mean():.3f} Â± {results.std():.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1Eig8PwQCcv"
      },
      "source": [
        "#### Logatrithmic Loss\n",
        "\n",
        "Logarithmic loss (or logloss) is a performance metric for evaluating the predictions of probabilities\n",
        "of membership to a given class. The scalar probability between 0 and 1 can be seen as a measure\n",
        "of confidence for a prediction by an algorithm. Predictions that are correct or incorrect are\n",
        "rewarded or punished proportionally to the confidence of the prediction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KNzhYhqkPogU"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming 'data' is your DataFrame\n",
        "X = data.iloc[:, 1:22]  # Select feature columns (adjusted for 22 features)\n",
        "Y = data.iloc[:, 0]  # Target column\n",
        "\n",
        "# Normalize features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Define cross-validation strategy\n",
        "kfold = KFold(n_splits=10, random_state=7, shuffle=True)  # Shuffling for better results\n",
        "\n",
        "# Define model\n",
        "model = LogisticRegression(solver='saga', max_iter=500)  # 'saga' works well for large datasets\n",
        "\n",
        "# Use Log Loss as the evaluation metric\n",
        "scoring = 'neg_log_loss'\n",
        "results = cross_val_score(model, X_scaled, Y, cv=kfold, scoring=scoring)\n",
        "\n",
        "# Print log loss correctly\n",
        "print(f\"Log Loss: {results.mean():.3f} ({results.std():.3f})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8AtOBCtQ4Ji"
      },
      "source": [
        "### Area Under ROC Curve\n",
        "\n",
        "Area under ROC Curve (or AUC for short) is a performance metric for binary classification\n",
        "problems. The AUC represents a modelâ€™s ability to discriminate between positive and negative\n",
        "classes.\n",
        "\n",
        "An area of 1.0 represents a model that made all predictions perfectly. An area of\n",
        "0.5 represents a model that is as good as random.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lYPwTnyZQBfy"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold, cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming 'data' is your DataFrame\n",
        "X = data.iloc[:, 1:22].values  # Select feature columns\n",
        "Y = data.iloc[:, 0].values  # Target column\n",
        "\n",
        "# Normalize features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Define cross-validation strategy\n",
        "kfold = KFold(n_splits=10, random_state=7, shuffle=True)\n",
        "\n",
        "# Define model with multi-class support\n",
        "model = OneVsRestClassifier(LogisticRegression(solver='saga', max_iter=500))  # or 'multinomial'\n",
        "\n",
        "# Use ROC AUC for multi-class classification\n",
        "scoring = 'roc_auc_ovr'  # Use 'roc_auc_ovo' for one-vs-one\n",
        "results = cross_val_score(model, X_scaled, Y, cv=kfold, scoring=scoring)\n",
        "\n",
        "# Print ROC AUC correctly\n",
        "print(f\"AUC: {results.mean():.3f} ({results.std():.3f})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0b2F8-sR6WW"
      },
      "source": [
        "#### Confusion Matrix\n",
        "\n",
        "A confusion matrix summarizes model performance by comparing predicted vs. actual class labels. Rows represent actual classes, columns represent predictions, and cells show correct and incorrect counts. It helps evaluate classification accuracy for both binary and multi-class problems."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iP7_O1ZTQ21V"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Assuming 'data' is your DataFrame\n",
        "X = data.iloc[:, 1:22].values  # Feature columns\n",
        "Y = data.iloc[:, 0].values  # Target column (multi-class)\n",
        "\n",
        "# Train-test split\n",
        "test_size = 0.33\n",
        "seed = 7\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n",
        "\n",
        "# Define logistic regression model with multi-class support\n",
        "model =\n",
        "model = OneVsRestClassifier(LogisticRegression(solver='saga', max_iter=500) ) # or 'multinomial'\n",
        "model.fit(X_train, Y_train)\n",
        "\n",
        "# Make predictions\n",
        "predicted = model.predict(X_test)\n",
        "\n",
        "# Compute confusion matrix\n",
        "matrix = confusion_matrix(Y_test, predicted)\n",
        "\n",
        "# Print the confusion matrix\n",
        "print(\"Confusion Matrix:\")\n",
        "print(matrix)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNahu1tZR51Q"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N7czczkJR27s"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP7rSlwpAOwjJMsgo0DlTBe",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}