{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb60a04b",
   "metadata": {},
   "source": [
    "### Sumiran Rai\n",
    "### Regd. No. 0 24040208007\n",
    "### Deep Learning Lab 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a35080",
   "metadata": {},
   "source": [
    "### List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cdb0353",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1.0, 2.0, 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fdccd28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31fa4d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "a[2] = 3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e1d5406",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 2.0, 3.0]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3044d6d",
   "metadata": {},
   "source": [
    "### Constructing our first tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ca9642b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sumir\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.ones(3) # Creates a one-dimensional tensor of size 3 filled with 1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89177a0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d4f4bcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(a[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9651a4b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 2.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[2] = 2.0\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc5165f",
   "metadata": {},
   "source": [
    "### Essence of tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00d75743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch tensors or NumPy arrays are contiguous memor blocks containing unboxec C numeric types rather than Python objects. Each element is a 32-bit float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54fec93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "points = torch.zeros(6) # Using.zeros is just a way to get an appropriately sized array.\n",
    "points[0] = 4.0\n",
    "points[1] = 1.0\n",
    "points[2] = 5.0\n",
    "points[3] = 3.0\n",
    "points[4] = 2.0\n",
    "points[5] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aab99604",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4., 1., 5., 3., 2., 1.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # We can also pass a Python list to the constructor, to the same effect:\n",
    "points = torch.tensor([4.0, 1.0, 5.0, 3.0, 2.0, 1.0])\n",
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fffbae52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.0, 1.0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(points[0]), float(points[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1cfdbd02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 1.],\n",
       "        [5., 3.],\n",
       "        [2., 1.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]]) #2D tensor\n",
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "28531fcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "73a651bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We could also use zeros or ones to initialize the tensor, providing the size as a tuple\n",
    "points = torch.zeros(3, 2)\n",
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e3b8ed76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
    "# Now we can access an individual element in the tensor using two indices.\n",
    "points[0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "04f12ef5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4., 1.])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can also access the first element in the tensor as we did before to get the 2D coordinates of the first point\n",
    "points[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d59770",
   "metadata": {},
   "source": [
    "### Indexing tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "70904587",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " some_list = list(range(6))\n",
    " some_list[:]\n",
    " some_list[1:4]\n",
    " some_list[1:]\n",
    " some_list[:4]\n",
    " some_list[:-1]\n",
    " some_list[1:4:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "25f71538",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[4., 1.],\n",
       "         [5., 3.],\n",
       "         [2., 1.]]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # In[54]:\n",
    " points[1:]\n",
    " points[1:, :]\n",
    " points[1:, 0]\n",
    " points[None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a2d61823",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_t = torch.randn(3, 5, 5) # shape [channels, rows, columns]\n",
    "weights = torch.tensor([0.2126, 0.7152, 0.0722])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5bda5a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_t = torch.randn(2, 3, 5, 5) # shape [batch, channels, rows, columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d8f8782c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 5]), torch.Size([2, 5, 5]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " img_gray_naive = img_t.mean(-3)\n",
    " batch_gray_naive = batch_t.mean(-3)\n",
    " img_gray_naive.shape, batch_gray_naive.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0ec60ac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3, 5, 5]), torch.Size([2, 3, 5, 5]), torch.Size([3, 1, 1]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " unsqueezed_weights = weights.unsqueeze(-1).unsqueeze_(-1)\n",
    " img_weights = (img_t * unsqueezed_weights)\n",
    " batch_weights = (batch_t * unsqueezed_weights)\n",
    " img_gray_weighted = img_weights.sum(-3)\n",
    " batch_gray_weighted = batch_weights.sum(-3)\n",
    " batch_weights.shape, batch_t.shape, unsqueezed_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d709f2ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5, 5])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_gray_weighted_fancy = torch.einsum('...chw,c->...hw', img_t, weights)\n",
    "batch_gray_weighted_fancy = torch.einsum('...chw,c->...hw', batch_t, weights)\n",
    "batch_gray_weighted_fancy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b7a3fb23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sumir\\AppData\\Local\\Temp\\ipykernel_31088\\2040007778.py:1: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\c10/core/TensorImpl.h:1938.)\n",
      "  weights_named = torch.tensor([0.2126, 0.7152, 0.0722], names=['channels'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.2126, 0.7152, 0.0722], names=('channels',))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " weights_named = torch.tensor([0.2126, 0.7152, 0.0722], names=['channels'])\n",
    " weights_named"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "10908fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img named: torch.Size([3, 5, 5]) ('channels', 'rows', 'columns')\n",
      "batch named: torch.Size([2, 3, 5, 5]) (None, 'channels', 'rows', 'columns')\n"
     ]
    }
   ],
   "source": [
    " img_named = img_t.refine_names(..., 'channels', 'rows', 'columns')\n",
    " batch_named = batch_t.refine_names(..., 'channels', 'rows', 'columns')\n",
    " print(\"img named:\", img_named.shape, img_named.names)\n",
    " print(\"batch named:\", batch_named.shape, batch_named.names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f4117f71",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (1483852383.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[28], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    weights_aligned.shape, weights_aligned.names\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "weights_aligned = weights_named.align_as(img_named)\n",
    " weights_aligned.shape, weights_aligned.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abfa4b6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'weights_aligned' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m gray_named \u001b[38;5;241m=\u001b[39m (img_named \u001b[38;5;241m*\u001b[39m \u001b[43mweights_aligned\u001b[49m)\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchannels\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m gray_named\u001b[38;5;241m.\u001b[39mshape, gray_named\u001b[38;5;241m.\u001b[39mnames\n",
      "\u001b[1;31mNameError\u001b[0m: name 'weights_aligned' is not defined"
     ]
    }
   ],
   "source": [
    " gray_named = (img_named * weights_aligned).sum('channels')\n",
    " gray_named.shape, gray_named.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d76153b",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error when attempting to broadcast dims ['channels', 'rows', 'columns'] and dims ['channels']: dim 'columns' and dim 'channels' are at the same position from the right but do not match.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m gray_named \u001b[38;5;241m=\u001b[39m (\u001b[43mimg_named\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mweights_named\u001b[49m)\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchannels\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error when attempting to broadcast dims ['channels', 'rows', 'columns'] and dims ['channels']: dim 'columns' and dim 'channels' are at the same position from the right but do not match."
     ]
    }
   ],
   "source": [
    " gray_named = (img_named[..., :3] * weights_named).sum('channels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc334016",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gray_named' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m gray_plain \u001b[38;5;241m=\u001b[39m \u001b[43mgray_named\u001b[49m\u001b[38;5;241m.\u001b[39mrename(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m      2\u001b[0m gray_plain\u001b[38;5;241m.\u001b[39mshape, gray_plain\u001b[38;5;241m.\u001b[39mnames\n",
      "\u001b[1;31mNameError\u001b[0m: name 'gray_named' is not defined"
     ]
    }
   ],
   "source": [
    " gray_plain = gray_named.rename(None)\n",
    " gray_plain.shape, gray_plain.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d05ae13",
   "metadata": {},
   "outputs": [],
   "source": [
    " double_points = torch.ones(10, 2, dtype=torch.double)\n",
    " short_points = torch.tensor([[1, 2], [3, 4]], dtype=torch.short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fdec37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int16"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " short_points.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92408b4b",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (3992480436.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[46], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    short_points = torch.ones(10, 2).short()\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "double_points = torch.zeros(10, 2).double()\n",
    " short_points = torch.ones(10, 2).short()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cdd4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    " double_points = torch.zeros(10, 2).to(torch.double)\n",
    " short_points = torch.ones(10, 2).to(dtype=torch.short)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39e55cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0.], dtype=torch.float64)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " points_64 = torch.rand(5, dtype=torch.double)\n",
    " points_short = points_64.to(torch.short)\n",
    " points_64 * points_short # works from PyTorch 1.3 onwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40888aed",
   "metadata": {},
   "outputs": [],
   "source": [
    " a = torch.ones(3, 2)\n",
    " a_t = torch.transpose(a, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3849441",
   "metadata": {},
   "outputs": [],
   "source": [
    " a.shape, a_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e40dea3",
   "metadata": {},
   "outputs": [],
   "source": [
    " a = torch.ones(3, 2)\n",
    " a_t = a.transpose(0, 1)\n",
    " a.shape, a_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0090cbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    " points = torch.tensor([[4.0,1.0], [5.0, 3.0], [2.0, 1.0]])\n",
    " points.storage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a29ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    " points_storage = points.storage()\n",
    " points_storage[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1b752c",
   "metadata": {},
   "outputs": [],
   "source": [
    " points.storage()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76e12ce",
   "metadata": {},
   "outputs": [],
   "source": [
    " points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
    " points_storage = points.storage()\n",
    " points_storage[0] = 2.0\n",
    " points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc283ec",
   "metadata": {},
   "outputs": [],
   "source": [
    " a = torch.ones(3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff52970",
   "metadata": {},
   "outputs": [],
   "source": [
    " a.zero_()\n",
    " a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2698ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    " points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
    " second_point = points[1]\n",
    " second_point.storage_offset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d07e50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_point.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263439ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_point.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ef76cb",
   "metadata": {},
   "outputs": [],
   "source": [
    " points.stride()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca92e32",
   "metadata": {},
   "outputs": [],
   "source": [
    " second_point = points[1]\n",
    " second_point.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbbfc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    " second_point.storage_offset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1f5a98",
   "metadata": {},
   "outputs": [],
   "source": [
    " second_point.stride()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6063f5",
   "metadata": {},
   "outputs": [],
   "source": [
    " points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
    " second_point = points[1]\n",
    " second_point[0] = 10.0\n",
    " points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93613e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
    " second_point = points[1].clone()\n",
    " second_point[0] = 10.0\n",
    " points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71adbcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    " points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
    " points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a56c47ce",
   "metadata": {},
   "outputs": [],
   "source": [
    " points_t = points.t()\n",
    " points_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc5fe0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "id(points.storage()) == id(points_t.storage())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47537ee",
   "metadata": {},
   "outputs": [],
   "source": [
    " points.stride()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89e7575",
   "metadata": {},
   "outputs": [],
   "source": [
    "points_t.stride()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e8fbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    " some_t = torch.ones(3, 4, 5)\n",
    " transpose_t = some_t.transpose(0, 2)\n",
    " some_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96505b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    " transpose_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf56c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_t.stride()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee6f7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    " transpose_t.stride()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8abef6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'points' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mpoints\u001b[49m\u001b[38;5;241m.\u001b[39mis_contiguous()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'points' is not defined"
     ]
    }
   ],
   "source": [
    " points.is_contiguous()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8b828508",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'points_t' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mpoints_t\u001b[49m\u001b[38;5;241m.\u001b[39mis_contiguous()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'points_t' is not defined"
     ]
    }
   ],
   "source": [
    " points_t.is_contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b1595f",
   "metadata": {},
   "outputs": [],
   "source": [
    " points = torch.tensor([[4.0,1.0], [5.0, 3.0], [2.0, 1.0]])\n",
    " points_t =points.t()\n",
    " points_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cff23b",
   "metadata": {},
   "outputs": [],
   "source": [
    " points_t.storage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98df4e74",
   "metadata": {},
   "outputs": [],
   "source": [
    " points_t.stride()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bde9c63",
   "metadata": {},
   "outputs": [],
   "source": [
    " points_t_cont = points_t.contiguous()\n",
    " points_t_cont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6768edba",
   "metadata": {},
   "outputs": [],
   "source": [
    " points_t_cont.stride()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9e0d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    " points_t_cont.storage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afcec16",
   "metadata": {},
   "outputs": [],
   "source": [
    " points_gpu = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]], device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ad37bd",
   "metadata": {},
   "outputs": [],
   "source": [
    " points_gpu = points.to(device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ec232f",
   "metadata": {},
   "outputs": [],
   "source": [
    " points_gpu = points.to(device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b1c11e",
   "metadata": {},
   "outputs": [],
   "source": [
    " points = 2 * points\n",
    " points_gpu = 2 * points.to(device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8f88c2",
   "metadata": {},
   "outputs": [],
   "source": [
    " points_gpu = points_gpu + 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16978844",
   "metadata": {},
   "outputs": [],
   "source": [
    "points_cpu = points_gpu.to(device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7745220e",
   "metadata": {},
   "outputs": [],
   "source": [
    "points_gpu = points.cuda()\n",
    " points_gpu = points.cuda(0)\n",
    " points_cpu = points_gpu.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294b362f",
   "metadata": {},
   "outputs": [],
   "source": [
    "points = torch.ones(3, 4)\n",
    " points_np = points.numpy()\n",
    " points_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecc1247",
   "metadata": {},
   "outputs": [],
   "source": [
    " points = torch.from_numpy(points_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3dd7ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    " torch.save(points, '../data/p1ch3/ourpoints.t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea102e6",
   "metadata": {},
   "outputs": [],
   "source": [
    " with open('../data/p1ch3/ourpoints.t','wb') as f:\n",
    " torch.save(points, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26931c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    " points = torch.load('../data/p1ch3/ourpoints.t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f6c578",
   "metadata": {},
   "outputs": [],
   "source": [
    " with open('../data/p1ch3/ourpoints.t','rb') as f:\n",
    " points = torch.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1562cc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    " import h5py\n",
    " f = h5py.File('../data/p1ch3/ourpoints.hdf5', 'w')\n",
    " dset = f.create_dataset('coords', data=points.numpy())\n",
    " f.close("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42adabf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File('../data/p1ch3/ourpoints.hdf5', 'r')\n",
    " dset = f['coords']\n",
    " last_points = dset[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24571bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    " # In[63]:\n",
    " last_points = torch.from_numpy(dset[-2:])\n",
    " f.close("
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
